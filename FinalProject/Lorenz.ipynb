{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique #2 : Create interesting visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'state', 'cases', 'deaths', 'abbreviation'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata= \"finalDataset.csv\"\n",
    "df = pd.read_csv(mydata) \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200121</td>\n",
       "      <td>Washington</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200122</td>\n",
       "      <td>Washington</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200123</td>\n",
       "      <td>Washington</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200124</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200124</td>\n",
       "      <td>Washington</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date       state  cases  deaths abbreviation\n",
       "0  20200121  Washington      1       0           WA\n",
       "1  20200122  Washington      1       0           WA\n",
       "2  20200123  Washington      1       0           WA\n",
       "3  20200124    Illinois      1       0           IL\n",
       "4  20200124  Washington      1       0           WA"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(\"finalDataset.csv\", \"r\")\n",
    "text = ''.join([i for i in text]) \\\n",
    "    .replace(\"-\", \"\")\n",
    "x = open(\"finalDataset.csv\",\"w\")\n",
    "x.writelines(text)\n",
    "x.close()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2061 entries, 0 to 2060\n",
      "Data columns (total 5 columns):\n",
      "date            2061 non-null int64\n",
      "state           2061 non-null object\n",
      "cases           2061 non-null int64\n",
      "deaths          2061 non-null int64\n",
      "abbreviation    2061 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 80.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape of XTrain: (1318, 4)\n",
      "y_train Shape of YTrain: (1318, 1)\n",
      "X_test Shape of XTest: (413, 4)\n",
      "y_test Shape of YTest: (413, 1)\n",
      "Shape of XValidation: (330, 4)\n",
      "Shape of YValidation: (330, 1)\n"
     ]
    }
   ],
   "source": [
    "#split dataset in target and other\n",
    "target = ['deaths']\n",
    "other = ['date', 'state', 'cases', 'abbreviation']\n",
    "\n",
    "X = df[other]\n",
    "y = df[target] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1) # 50% training and 20% test\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = 0.2, random_state=2)# 50% training and 20% Validation\n",
    "\n",
    "#CHECK We expect the training features number of columns to match the testing feature number of columns and the number of rows to match for the respective training and testing features and the labels\n",
    "print('X_train Shape of XTrain:', X_train.shape)\n",
    "print('y_train Shape of YTrain:', y_train.shape)\n",
    "print('X_test Shape of XTest:', X_test.shape)\n",
    "print('y_test Shape of YTest:', y_test.shape)\n",
    "print('Shape of XValidation:', X_validation.shape)\n",
    "print('Shape of YValidation:', y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "cases\n",
      "deaths\n",
      "state_Alabama\n",
      "state_Alaska\n",
      "state_Arizona\n",
      "state_Arkansas\n",
      "state_California\n",
      "state_Colorado\n",
      "state_Connecticut\n",
      "state_Delaware\n",
      "state_DistrictofColumbia\n",
      "state_Florida\n",
      "state_Georgia\n",
      "state_Hawaii\n",
      "state_Idaho\n",
      "state_Illinois\n",
      "state_Indiana\n",
      "state_Iowa\n",
      "state_Kansas\n",
      "state_Kentucky\n",
      "state_Louisiana\n",
      "state_Maine\n",
      "state_Maryland\n",
      "state_Massachusetts\n",
      "state_Michigan\n",
      "state_Minnesota\n",
      "state_Mississippi\n",
      "state_Missouri\n",
      "state_Montana\n",
      "state_Nebraska\n",
      "state_Nevada\n",
      "state_New Hampshire\n",
      "state_New Jersey\n",
      "state_New Mexico\n",
      "state_New York\n",
      "state_North Carolina\n",
      "state_North Dakota\n",
      "state_Ohio\n",
      "state_Oklahoma\n",
      "state_Oregon\n",
      "state_Pennsylvania\n",
      "state_Rhode Island\n",
      "state_South Carolina\n",
      "state_South Dakota\n",
      "state_Tennessee\n",
      "state_Texas\n",
      "state_Utah\n",
      "state_Vermont\n",
      "state_Virginia\n",
      "state_Washington\n",
      "state_West Virginia\n",
      "state_Wisconsin\n",
      "state_Wyoming\n",
      "abbreviation_AK\n",
      "abbreviation_AL\n",
      "abbreviation_AR\n",
      "abbreviation_AZ\n",
      "abbreviation_CA\n",
      "abbreviation_CO\n",
      "abbreviation_CT\n",
      "abbreviation_DC\n",
      "abbreviation_DE\n",
      "abbreviation_FL\n",
      "abbreviation_GA\n",
      "abbreviation_HI\n",
      "abbreviation_IA\n",
      "abbreviation_ID\n",
      "abbreviation_IL\n",
      "abbreviation_IN\n",
      "abbreviation_KS\n",
      "abbreviation_KY\n",
      "abbreviation_LA\n",
      "abbreviation_MA\n",
      "abbreviation_MD\n",
      "abbreviation_ME\n",
      "abbreviation_MI\n",
      "abbreviation_MN\n",
      "abbreviation_MO\n",
      "abbreviation_MS\n",
      "abbreviation_MT\n",
      "abbreviation_NC\n",
      "abbreviation_ND\n",
      "abbreviation_NE\n",
      "abbreviation_NH\n",
      "abbreviation_NJ\n",
      "abbreviation_NM\n",
      "abbreviation_NV\n",
      "abbreviation_NY\n",
      "abbreviation_OH\n",
      "abbreviation_OK\n",
      "abbreviation_OR\n",
      "abbreviation_PA\n",
      "abbreviation_RI\n",
      "abbreviation_SC\n",
      "abbreviation_SD\n",
      "abbreviation_TN\n",
      "abbreviation_TX\n",
      "abbreviation_UT\n",
      "abbreviation_VA\n",
      "abbreviation_VT\n",
      "abbreviation_WA\n",
      "abbreviation_WI\n",
      "abbreviation_WV\n",
      "abbreviation_WY\n"
     ]
    }
   ],
   "source": [
    "#SKLearn only takes # so I have to change all of the Strings to #\n",
    "#use pd.concat to join the new columns with your original dataframe\n",
    "df = pd.concat([df,pd.get_dummies(df['state'], prefix='state')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['abbreviation'], prefix='abbreviation')],axis=1)\n",
    "                     \n",
    "# get rid of the original column\n",
    "df.drop(['state'],axis=1, inplace=True)\n",
    "df.drop(['abbreviation'],axis=1, inplace=True)\n",
    "\n",
    "#show all column names\n",
    "for col in df.columns: \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'DistrictofColumbia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fb74c2816a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train Decision Tree Classifer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Predict the response for test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'DistrictofColumbia'"
     ]
    }
   ],
   "source": [
    "# Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "    \n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results,\"\\n\") \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred),\"\\n\")\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(clf.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(clf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
